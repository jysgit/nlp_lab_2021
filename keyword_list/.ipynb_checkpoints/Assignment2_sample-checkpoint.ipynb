{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Assignment2_sample.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"VtF-xkTxQqTL"},"source":["# Assignment02: Find Academic Keyword List\n","Academic Keywords are the words we seldom use ordinarily, but often use in Academic articles. \"This shows\" and \"in conclusion\" are examples of Academic Keywords. This assignment want you to use Rank Ratio and compare two dataset to find Academic Keyword List(AKL).\n","<br><br>\n","One dataset is taken from [`British Academic Written English Corpus(BAWE)`](https://www.coventry.ac.uk/research/research-directories/current-projects/2015/british-academic-written-english-corpus-bawe/), which collect a record of proficient university-level student writing. Hence, BAWE can be seen as Academic data. Another one is called [`Web1T`](https://catalog.ldc.upenn.edu/LDC2006T13), which is presented by Google. Web1T colloct 1 trillion words of English Web, so we can treat it as the representative of common words. "]},{"cell_type":"markdown","metadata":{"id":"FvbEQL76QqTQ"},"source":["## N-gram counting\n","This part is almost same as what you need to do in Assignment01. The way to find N-gram is the same as Assignment01. However, tokenization and calculating frequency are a little different. The rules of tokenization in this Assignment are:\n"," 1. Ignore case (e.g., \"The\" is the same as \"the\")\n"," 2. Split by white spaces <s>and punctuations</s>\n"," 3. Ignore all punctuation\n","<br><br>\n","\n","As for calculating frequency, we want you calculating <u>document frequency</u> in this Assignment. <br>What is document frequency? \n","<br>Article 1: \n","> We all know that water masses in the ocean are thought to be transferred by the wind. ...\n","\n","Althought there are at least 2 \"the\" in Article 1, the document frequency of \"the\" is still 1 in this article.<br> No mater how many times does \"the\" show up in Article 1, the document frquency of it is always 1.<br>\n","Article 2: \n","> The film Dantes Peak is about a dormant volcano that suddenly erupts and threatens the nearby town. ...\n","\n","Considering the Article 1 and 2, the document frequency of \"the\" is 2 now.<br>\n","Document frequency can reduce the influence of terms, like \"NLP\".\n","<br><br>\n","<span style=\"color: red\">[ TODO ]</span> Try to modify the functions coded in Assignment01 to <u>calculate document frequencies of all unigram.</u>.\n","\n","Google has calculated the frequency of N-gram, so you only need to do it on BAWE."]},{"cell_type":"code","metadata":{"id":"NRC_RJVlQqTR"},"source":["import time\n","start_time = time.time()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6kFgxIi-QqTS"},"source":["import os\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_HqR0G5xQqTT"},"source":["import string\n","def tokenize(text):\n","    #### [ TODO ] transform to lower case\n","    text = text.lower()\n","    ### [ TODO ] seperate the words\n","    tokens = text.translate(str.maketrans('', '', string.punctuation)).split(' ')\n","    return tokens\n","from collections import Counter\n","def calculate_frequency(tokens):\n","    # [ TODO ]\n","    frequency = dict(Counter(tokens))\n","    return frequency\n","def get_ngram(tokens, n=2):\n","    return [' '.join(tokens[i:i+n]) for i in range(len(tokens)-1)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJ4NO_KHQqTT"},"source":["file_path = os.path.join('data', 'BAWE.txt')\n","BAWE_unigram = []\n","#### [ TODO ] calculate document frequency of unigram in BAWE\n","with open(file_path, 'r') as f:\n","    for text in f.readlines():\n","        tokens = tokenize(text.rstrip(\"/n\"))\n","        BAWE_unigram += list(set(get_ngram(tokens, n=1)))\n","BAWE_unigram_counter = calculate_frequency(BAWE_unigram)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qq7LtaSHQqTU"},"source":["# Read Web1T Data\n","file_path = os.path.join('data', 'Web1T_unigram.txt')\n","Web1T_unigram_counter = {}\n","with open(file_path,'r') as f:\n","    for line in f.readlines():\n","        line=line.rstrip(\"\\n\").split(\"\\t\")\n","        Web1T_unigram_counter[line[0]] = int(line[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qK5t8MIQQqTV"},"source":["## Rank\n","Rank unigrms by their frequencies. The higher the frequency, the higher the rank.(The most frequent unigram ranks 1.)<br>\n","<span style=\"color: red\">[ TODO ]</span> <u>Rank unigrams for Web1T and BAWE.</u>."]},{"cell_type":"code","metadata":{"id":"X6DNRgnBQqTW"},"source":["Web1T_unigram_Rank = {}\n","#### [ TODO ] Rank unigrams for Web1T\n","for i,unigram in enumerate(sorted(Web1T_unigram_counter.items(), key=lambda item: item[1],reverse=True)):\n","    Web1T_unigram_Rank[unigram[0]] = i+1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxMigzCqQqTW"},"source":["BAWE_unigram_Rank = {}\n","#### [ TODO ] Rank unigrams for BAWE\n","for i,unigram in enumerate(sorted(BAWE_unigram_counter.items(), key=lambda item: item[1],reverse=True)):\n","    BAWE_unigram_Rank[unigram[0]] = i+1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LxFAWcsoQqTX"},"source":["## Calculate Rank Ratio\n","In this step, you need to map the same unigram in two dataset, and caalculate the Rank Ratio of unigram in BAWE.  <br>Please follow the formula for calculating Rank Ratio:<br> \n","<br>\n","<img src=\"https://imgur.com/vmK7Q1K.jpg\" width=30%><br>\n","If the unigram doesn't appear in Web1T, the rank of it is treated as 1.\n","\n","<span style=\"color: red\">[ TODO ]</span> Please calculate all rank ratios of unigrams in BAWE."]},{"cell_type":"code","metadata":{"id":"hhx_d4yPQqTX"},"source":["#### [TODO] calculate all rank ratios of unigrams in BAWE\n","unigram_result = {}\n","for term,rank in BAWE_unigram_Rank.items():\n","    if term in Web1T_unigram_Rank.keys():\n","        unigram_result[term] = Web1T_unigram_Rank[term]/rank\n","    else:\n","        unigram_result[term] = 1/rank"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-y3oZSq8QqTY"},"source":["## sort the result\n","<span style=\"color: red\">[ TODO ]</span> Please show top 30 uigrams in Rank Ratio and the value of their Rank Ratio in this format: \n","<br>\n","<img src=\"https://imgur.com/AEkiCRr.jpg\" width=50%>"]},{"cell_type":"code","metadata":{"id":"as16bYyfQqTY","outputId":"77efe892-c995-4373-bec5-b60adde5911f"},"source":["#### [ TODO ] souw the result\n","print(f'rank\\tunigram\\t\\t\\t\\tRank Ratio')\n","for i,one in enumerate(sorted(unigram_result.items(), key=lambda item: item[1],reverse=True)[:30]):\n","    if len(one[0])<8:\n","        print(f'{i+1}\\t{one[0]}\\t\\t\\t\\t{round(one[1],4)}')\n","    elif len(one[0])>=16:\n","        print(f'{i+1}\\t{one[0]}\\t\\t{round(one[1],4)}')\n","    else:\n","        print(f'{i+1}\\t{one[0]}\\t\\t\\t{round(one[1],4)}')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["rank\tunigram\t\t\t\tRank Ratio\n","1\tcannot\t\t\t\t598.8483\n","2\tsocietys\t\t\t67.7626\n","3\tshortterm\t\t\t58.5846\n","4\tsocalled\t\t\t49.1186\n","5\tlargescale\t\t\t46.0125\n","6\tandor\t\t\t\t35.6575\n","7\tmiddleclass\t\t\t35.5603\n","8\tlongterm\t\t\t31.1305\n","9\tfirstly\t\t\t\t28.6082\n","10\tcrossborder\t\t\t28.3023\n","11\tcosteffective\t\t\t27.7408\n","12\tttest\t\t\t\t27.7113\n","13\tlongrun\t\t\t\t27.0455\n","14\tconclusion\t\t\t26.9133\n","15\ttwoway\t\t\t\t25.9868\n","16\tcountrys\t\t\t25.8469\n","17\twellknown\t\t\t25.5356\n","18\tcrosscultural\t\t\t24.567\n","19\tlatters\t\t\t\t24.5357\n","20\tgermanys\t\t\t23.7711\n","21\tlonglasting\t\t\t23.2488\n","22\ttrudgill\t\t\t21.8957\n","23\thighquality\t\t\t21.8716\n","24\thighlevel\t\t\t21.1928\n","25\tgleitman\t\t\t21.1731\n","26\tthatchers\t\t\t21.0268\n","27\txrays\t\t\t\t20.8775\n","28\tdarwins\t\t\t\t20.8727\n","29\tsibilance\t\t\t20.3009\n","30\tasias\t\t\t\t19.9919\n"]}]},{"cell_type":"code","metadata":{"id":"Z4-E3SRcQqTZ","outputId":"b2231808-6ef4-4d1f-d8c1-d360f6c5f4d1"},"source":["print(\"--- %s seconds ---\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["--- 4.591401100158691 seconds ---\n"]}]},{"cell_type":"markdown","metadata":{"id":"cCK35fbaQqTZ"},"source":["## for Bigrams\n","<span style=\"color: red\">[ TODO ]</span> Do the Same Thing for Bigrams"]},{"cell_type":"code","metadata":{"id":"ZKGeX9LpQqTZ"},"source":["start_time = time.time()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPnhU3YVQqTa","outputId":"cce9aa71-ec44-4525-9e9d-803f8e7abf2f"},"source":["file_path = os.path.join('data', 'BAWE.txt')\n","BAWE_bigram = []\n","with open(file_path, 'r') as f:\n","    for text in f.readlines():\n","        tokens = tokenize(text.rstrip(\"/n\"))\n","        BAWE_bigram += list(set(get_ngram(tokens, n=2)))\n","BAWE_bigram_counter = calculate_frequency(BAWE_bigram)\n","\n","# Read Web1T Data\n","file_path = os.path.join('data', 'Web1T_bigram.txt')\n","Web1T_bigram_counter = {}\n","with open(file_path,'r') as f:\n","    for line in f.readlines():\n","        line=line.rstrip(\"\\n\").split(\"\\t\")\n","        Web1T_bigram_counter[line[0]] = int(line[1])\n","        \n","BAWE_bigram_Rank = {}\n","for i,bigram in enumerate(sorted(BAWE_bigram_counter.items(), key=lambda item: item[1],reverse=True)):\n","    BAWE_bigram_Rank[bigram[0]] = i+1\n","Web1T_bigram_Rank = {}\n","for i,bigram in enumerate(sorted(Web1T_bigram_counter.items(), key=lambda item: item[1],reverse=True)):\n","    Web1T_bigram_Rank[bigram[0]] = i+1\n","bigram_result = {}\n","for term,rank in BAWE_bigram_Rank.items():\n","    if term in Web1T_bigram_Rank.keys():\n","        bigram_result[term] = Web1T_bigram_Rank[term]/rank\n","    else:\n","        bigram_result[term] = 1/rank\n","print(f'rank\\tbigram\\t\\t\\t\\tRank Ratio')\n","for i,one in enumerate(sorted(bigram_result.items(), key=lambda item: item[1],reverse=True)[:30]):\n","    if len(one[0])<8:\n","        print(f'{i+1}\\t{one[0]}\\t\\t\\t\\t{round(one[1],4)}')\n","    elif len(one[0])>=16:\n","        print(f'{i+1}\\t{one[0]}\\t\\t{round(one[1],4)}')\n","    else:\n","        print(f'{i+1}\\t{one[0]}\\t\\t\\t{round(one[1],4)}')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["rank\tbigram\t\t\t\tRank Ratio\n","1\tin conclusion\t\t\t515.1753\n","2\thowever this\t\t\t418.7165\n","3\thowever the\t\t\t372.5714\n","4\thowever in\t\t\t285.3752\n","5\thowever it\t\t\t247.1333\n","6\tthis essay\t\t\t227.7991\n","7\thowever there\t\t\t218.3365\n","8\tthe british\t\t\t185.5634\n","9\tthe european\t\t\t155.118\n","10\tthis suggests\t\t\t139.4575\n","11\tthis shows\t\t\t107.25\n","12\tanalysis the\t\t\t92.5134\n","13\tsee appendix\t\t\t90.3399\n","14\ttherefore it\t\t\t90.3056\n","15\thowever a\t\t\t89.8123\n","16\ttherefore the\t\t\t86.43\n","17\tmethod the\t\t\t77.0229\n","18\tconclusion in\t\t\t65.4173\n","19\tthe uk\t\t\t\t63.2821\n","20\thowever he\t\t\t62.5608\n","21\thowever to\t\t\t61.4795\n","22\tthe united\t\t\t61.333\n","23\ta persons\t\t\t60.4332\n","24\ttherefore this\t\t\t59.5873\n","25\tsystem the\t\t\t58.8253\n","26\texample it\t\t\t58.5033\n","27\ti shall\t\t\t\t58.356\n","28\tdespite this\t\t\t57.8208\n","29\tdevelopment the\t\t\t56.8733\n","30\tin england\t\t\t56.5129\n"]}]},{"cell_type":"code","metadata":{"id":"7Oba2CFgQqTa","outputId":"84ea9616-513c-4fd6-ab22-36c6c489e57a"},"source":["print(\"--- %s seconds ---\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["--- 10.236293077468872 seconds ---\n"]}]},{"cell_type":"markdown","metadata":{"id":"5oeUM8RoQqTb"},"source":["## TA's Notes\n","\n","If you complete the Assignment, please use [this link](https://docs.google.com/spreadsheets/d/1QGeYl5dsD9sFO9SYg4DIKk-xr-yGjRDOOLKZqCLDv2E/edit#gid=40492256) to reserve demo time.  \n","The score is only given after TAs review your implementation, so <u>**make sure you make a appointment with a TA before you miss the deadline**</u> .  <br>After demo, please upload your assignment to eeclass. You just need to hand in this ipynb file and rename it as XXXXXXXXX(Your student ID).ipynb.\n","<br>Note that **late submission will not be allowed**.  "]}]}